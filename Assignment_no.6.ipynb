{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c494ace9-a84d-4b8e-8cb5-1a286f22ebe8",
   "metadata": {},
   "source": [
    "Name: Jignesh Tathe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df001cb0-7899-4c32-b76e-2e733a143799",
   "metadata": {},
   "source": [
    "Branch: CO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b502c47d-1d31-42f9-91a1-801753d55b82",
   "metadata": {},
   "source": [
    "Assignment No. 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197d386-f913-4a20-9b3d-a168e8369064",
   "metadata": {},
   "source": [
    "# Q.no. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e3a6c1-791c-403a-82ca-398c061226d3",
   "metadata": {},
   "source": [
    "**Scrape all product names and prices from the first two pages of \"Books to Scrape\" (http://books.toscrape.com/). Handle simple pagination and structure the output as a list of dictionaries with 'title' and 'price'.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db52ee6-6a98-4f13-a480-03df8360fcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Books to scrape (first 2 pages):\n",
      "{'title': 'In Her Wake', 'price': 'Â£12.84'}\n",
      "{'title': 'How Music Works', 'price': 'Â£37.32'}\n",
      "{'title': 'Foolproof Preserving: A Guide to Small Batch Jams, Jellies, Pickles, Condiments, and More: A Foolproof Guide to Making Small Batch Jams, Jellies, Pickles, Condiments, and More', 'price': 'Â£30.52'}\n",
      "{'title': 'Chase Me (Paris Nights #2)', 'price': 'Â£25.27'}\n",
      "{'title': 'Black Dust', 'price': 'Â£34.53'}\n",
      "{'title': 'Birdsong: A Story in Pictures', 'price': 'Â£54.64'}\n",
      "{'title': \"America's Cradle of Quarterbacks: Western Pennsylvania's Football Factory from Johnny Unitas to Joe Montana\", 'price': 'Â£22.50'}\n",
      "{'title': 'Aladdin and His Wonderful Lamp', 'price': 'Â£53.13'}\n",
      "{'title': 'Worlds Elsewhere: Journeys Around Shakespeareâ\\x80\\x99s Globe', 'price': 'Â£40.30'}\n",
      "{'title': 'Wall and Piece', 'price': 'Â£44.18'}\n",
      "{'title': 'The Four Agreements: A Practical Guide to Personal Freedom', 'price': 'Â£17.66'}\n",
      "{'title': 'The Five Love Languages: How to Express Heartfelt Commitment to Your Mate', 'price': 'Â£31.05'}\n",
      "{'title': 'The Elephant Tree', 'price': 'Â£23.82'}\n",
      "{'title': 'The Bear and the Piano', 'price': 'Â£36.89'}\n",
      "{'title': \"Sophie's World\", 'price': 'Â£15.94'}\n",
      "{'title': 'Penny Maybe', 'price': 'Â£33.29'}\n",
      "{'title': 'Maude (1883-1993):She Grew Up with the country', 'price': 'Â£18.02'}\n",
      "{'title': 'In a Dark, Dark Wood', 'price': 'Â£19.63'}\n",
      "{'title': 'Behind Closed Doors', 'price': 'Â£52.22'}\n",
      "{'title': \"You can't bury them all: Poems\", 'price': 'Â£33.63'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "books_data = []\n",
    "base_url = \"http://books.toscrape.com/catalogue/page-{}.html\"\n",
    "\n",
    "for page in range(1, 3):\n",
    "    url = base_url.format(page)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "\n",
    "for book in soup.select(\".product_pod\"):\n",
    "    title = book.h3.a[\"title\"]\n",
    "    price = book.select_one(\".price_color\").text.strip()\n",
    "    books_data.append({\"title\": title, \"price\": price})\n",
    "\n",
    "print(\"\\nBooks to scrape (first 2 pages):\")\n",
    "for b in books_data:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96fcb279-5e42-49a8-80b2-0aaf523fc216",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cf31e53-1941-40c6-9e2a-1234b5e42f97",
   "metadata": {},
   "source": [
    "# Q.no. 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a048b5-35fb-405a-bb1b-a64226743bf2",
   "metadata": {},
   "source": [
    "**Extract the current weather descriptions (like ‘clear’, ‘cloudy’) and temperatures for at least five cities from a public weather site (such as https://www.weather.com or https://wttr.in). Present your data in a tabular format (city, description, temperature).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c37ff82-6612-4132-b307-a88e5ec07cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weather Data:\n",
      "        city    description temperature\n",
      "0      Paris          Sunny       +29°C\n",
      "1      Dubai          Sunny       +42°C\n",
      "2  Singapore  Partly cloudy       +27°C\n",
      "3     Mumbai           Haze       +31°C\n",
      "4      Tokyo  Partly cloudy       +28°C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cities = [\"Paris\", \"Dubai\", \"Singapore\", \"Mumbai\", \"Tokyo\"]\n",
    "weather_data = []\n",
    "\n",
    "for city in cities:\n",
    "    url = f\"https://wttr.in/{city}?format=%C+%t\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        description_temp = response.text.strip()\n",
    "        try:\n",
    "            description, temp = description_temp.rsplit(\" \", 1)\n",
    "        except ValueError:\n",
    "            description, temp = description_temp, \"\"\n",
    "        weather_data.append({\"city\": city, \"description\": description, \"temperature\": temp})\n",
    "\n",
    "weather_df = pd.DataFrame(weather_data)\n",
    "print(\"\\nWeather Data:\")\n",
    "print(weather_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b79e7d7-a679-4357-9483-0b5af7f44c13",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5524952f-279a-4c58-bd27-11b9f607a5fd",
   "metadata": {},
   "source": [
    "# Q.no. 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce48cd4-336b-416c-88d3-53b7fb1c3518",
   "metadata": {},
   "source": [
    "**From the “Real Python Fake Jobs” board (https://realpython.github.io/fake-jobs/), gather all job titles, companies, and locations listed on the first three pages. Save the results as a CSV file. Be sure to loop through the pagination and properly parse the HTML for structured data extraction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35a71e0f-29e5-4009-8242-3abb9f7a5605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to task_6.csv\n"
     ]
    }
   ],
   "source": [
    "jobs_data = []\n",
    "jobs_base_url = \"https://realpython.github.io/fake-jobs/page-{}.html\"\n",
    "\n",
    "for page in range(1, 4):\n",
    "    url = jobs_base_url.format(page)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    for job_card in soup.select(\".card-content\"):\n",
    "        title = job_card.find(\"h1\", class_=\"title\").text.strip()\n",
    "        company = job_card.find(\"h3\", class_=\"company\").text.strip()\n",
    "        location = job_card.find(\"p\", class_=\"location\").text.strip()\n",
    "        jobs_data.append({\"title\": title, \"company\": company, \"location\": location})\n",
    "\n",
    "jobs_df = pd.DataFrame(jobs_data)\n",
    "jobs_df.to_csv(\"task_6\", index=False)\n",
    "\n",
    "print(\"Data saved to task_6.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
